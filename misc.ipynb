{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqt9kDmkTv7c1456xvYVjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yogananth-r/face-recognition/blob/main/misc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVLcgqhn4mrV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "# Load the cascade classifier for face detection\n",
        "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# Load the photos in the folder\n",
        "def get_images_and_labels(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        # Load the image\n",
        "        #print(\"hi \",filename)\n",
        "        image = cv2.imread(os.path.join(folder, filename))\n",
        "        if image is None:\n",
        "          print(f\"Failed to load image: {filename}\")\n",
        "          continue\n",
        "\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect faces in the image\n",
        "        faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        # For each face, extract a sample and add it to the training data\n",
        "        for (x, y, w, h) in faces:\n",
        "            images.append(gray[y:y + h, x:x + w])\n",
        "            label_string = filename.split(\"_\")[1].split(\".\")[0]\n",
        "            #print(\"ls\",label_string)\n",
        "            if label_string:\n",
        "              labels.append(label_string)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "# Train the face recognition model\n",
        "def train_model(folder):\n",
        "    images, labels = get_images_and_labels(folder)\n",
        "\n",
        "    # Train the model using the Local Binary Patterns Histograms (LBPH) algorithm\n",
        "    model = cv2.face.LBPHFaceRecognizer_create()\n",
        "    labels = np.array(labels, dtype=np.int32)\n",
        "    model.train(images, np.array(labels))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Test the face recognition model\n",
        "def test_model(model, folder):\n",
        "    images, labels = get_images_and_labels(folder)\n",
        "    print(labels)\n",
        "    # Predict the labels for each image\n",
        "    predicted_labels = []\n",
        "    for image in images:\n",
        "        label, confidence = model.predict(image)\n",
        "        predicted_labels.append(label)\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    accuracy = np.count_nonzero(np.array(predicted_labels) == np.array(labels)) / len(labels)\n",
        "    return accuracy\n",
        "\n",
        "# Train and test the model\n",
        "model = train_model(\"/content/sample_data/data\")\n",
        "accuracy = test_model(model, \"/content/sample_data/data\")\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILbJaZT29F41",
        "outputId": "70d7ef36-2a69-4540-b8f0-3d105c102e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load image: .ipynb_checkpoints\n",
            "Failed to load image: .ipynb_checkpoints\n",
            "['11', '7', '5', '5', '10', '12', '1', '2', '3', '3', '8', '13', '4', '6', '6']\n",
            "Accuracy: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-07f0fb55021d>:59: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  accuracy = np.count_nonzero(np.array(predicted_labels) == np.array(labels)) / len(labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def use_camera():\n",
        "  js = Javascript('''\n",
        "    async function use_camera() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('use_camera()')\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open('photo.jpg', 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return len(binary)\n",
        "\n",
        "result = use_camera()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "myIM8fik4raz",
        "outputId": "d4c7cfc5-c442-44c1-8b13-a52c22d22b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function use_camera() {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(image):\n",
        "  face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "  image = cv2.imread(image)\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "  faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
        "  for (x, y, w, h) in faces:\n",
        "    face = gray[y:y + h, x:x + w]\n",
        "    label, confidence = model.predict(face)\n",
        "    \"\"\"if label in range(1,9):\n",
        "      label=\"yogi\"\n",
        "    else:\n",
        "      label=\"raju\" \"\"\"\n",
        "    print(\"Label: {} Confidence: {:.2f}%\".format(label, confidence))"
      ],
      "metadata": {
        "id": "dBsT54RhZ362"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(\"/content/photo.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_nA9-0DacS2",
        "outputId": "9f4e822e-00ef-4099-ba78-f3db00edb93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5 Confidence: 69.61%\n"
          ]
        }
      ]
    }
  ]
}